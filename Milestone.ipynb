{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7637d8a2",
   "metadata": {},
   "source": [
    "My project is making a machine learning micro service using a weighted Linear Regression and a weighted XGBoost. This is the code I used to train a model and make it presistant for the purpose of being able to be called later in an API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Weighted Linear Regression for F1 Predictions\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"dataset/F1_training_data.csv\")\n",
    "MODEL_PATH = Path(\"models/trained/linear_v0.1.joblib\")\n",
    "\n",
    "def load_data():\n",
    "    print(\"üìä Loading training data...\")\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"‚úÖ Loaded {len(df):,} rows\")\n",
    "    print(f\"   Years: {int(df['year'].min())} - {int(df['year'].max())}\")\n",
    "    print(f\"   Columns: {list(df.columns)}\")\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    print(\"\\nüîß Creating feature matrix...\")\n",
    "    \n",
    "    # Use ONLY numerical features (engineered features replace categorical ones)\n",
    "    feature_cols = [\n",
    "        'grid',                    # Starting position\n",
    "        'driver_avg_position',     # Driver's rolling avg finish\n",
    "        'driver_avg_points',       # Driver's rolling avg points\n",
    "        'driver_recent_form',      # Driver's weighted recent form\n",
    "        'track_avg_pos_change',    # Track overtaking metric\n",
    "        'driver_track_avg'         # Driver's performance at this track\n",
    "    ]\n",
    "    \n",
    "    print(f\"   Using features: {feature_cols}\")\n",
    "    \n",
    "    X = df[feature_cols].copy()\n",
    "    y = df['position'].copy()\n",
    "    \n",
    "    # Remove any rows with NaN (shouldn't be any after feature engineering)\n",
    "    mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    print(f\"‚úÖ Feature matrix ready: {len(X)} samples x {len(feature_cols)} features\")\n",
    "    print(f\"   Target range: {y.min():.0f} - {y.max():.0f}\")\n",
    "    \n",
    "    return X, y, df[mask]\n",
    "\n",
    "def create_weights(df):\n",
    "    print(\"\\n‚öñÔ∏è  Creating time-based weights (recent races matter more)...\")\n",
    "    years = df['year'].values\n",
    "    max_year = years.max()\n",
    "    \n",
    "    # Exponential decay: more recent years get higher weights\n",
    "    # decay_rate = 0.15 means each year back reduces weight by ~14%\n",
    "    decay_rate = 0.22\n",
    "    weights = np.exp(-(max_year - years) * decay_rate)\n",
    "    \n",
    "    print(f\"   Weight range: {weights.min():.3f} to {weights.max():.3f}\")\n",
    "    print(f\"   2018 weight: {weights[years == 2018].mean():.3f}\")\n",
    "    print(f\"   2025 weight: {weights[years == 2025].mean():.3f}\")\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def train_model(X, y, weights):\n",
    "    print(\"\\nüéØ Training weighted linear regression...\")\n",
    "    \n",
    "    # Split data for validation\n",
    "    X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(\n",
    "        X, y, weights, test_size=0.15, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"   Training samples: {len(X_train)}\")\n",
    "    print(f\"   Validation samples: {len(X_val)}\")\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # Train weighted linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train, sample_weight=w_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_score = model.score(X_train_scaled, y_train)\n",
    "    val_score = model.score(X_val_scaled, y_val)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val_scaled)\n",
    "    mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    \n",
    "    print(f\"\\nüìä Model Performance:\")\n",
    "    print(f\"   Training R¬≤: {train_score:.4f}\")\n",
    "    print(f\"   Validation R¬≤: {val_score:.4f}\")\n",
    "    print(f\"   Validation MAE: {mae:.2f} positions\")\n",
    "    print(f\"   Validation RMSE: {rmse:.2f} positions\")\n",
    "    \n",
    "    # Show feature importance (coefficients)\n",
    "    print(f\"\\nüìà Feature Coefficients:\")\n",
    "    for feat, coef in zip(X.columns, model.coef_):\n",
    "        print(f\"   {feat:25s}: {coef:+.4f}\")\n",
    "    \n",
    "    return model, scaler\n",
    "\n",
    "def save_model(model, scaler):\n",
    "    print(\"üíæ Saving model...\")\n",
    "    MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    package = {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'version': 'v0.1'\n",
    "    }\n",
    "    \n",
    "    joblib.dump(package, MODEL_PATH)\n",
    "    print(f\"‚úÖ Saved to {MODEL_PATH}\")\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"F1 Weighted Linear Regression Training\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    df = load_data()\n",
    "    X, y, df_clean = create_features(df)\n",
    "    weights = create_weights(df_clean)\n",
    "    model, scaler = train_model(X, y, weights)\n",
    "    save_model(model, scaler)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ Training complete!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nüìù Next steps:\")\n",
    "    print(\"   1. Model saved to: models/trained/linear_v0.1.joblib\")\n",
    "    print(\"   2. Update app/main.py to use the trained model\")\n",
    "    print(\"   3. Test predictions on 2025 races 19-24\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3e1b6",
   "metadata": {},
   "source": [
    "We then use the presistent model to predict the remaining races using an engineered CSV, and for testing purposes we used the 2024 grid posistion in order to predict our 2025 podium for the remain 6 races. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predict the last 6 races of F1 2025 season (races 19-24)\n",
    "- For completed races: compare predictions vs actual\n",
    "- For future races: generate predictions based on historical data\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "TRAINING_DATA = Path(\"dataset/F1_training_data.csv\")\n",
    "FULL_2025_DATA = Path(\"dataset/Formula1_2025Season_RaceResults.csv\")\n",
    "MODEL_PATH = Path(\"models/trained/linear_v0.1.joblib\")\n",
    "OUTPUT_PATH = Path(\"predictions/2025_races_19-24_predictions.csv\")\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the trained model\"\"\"\n",
    "    print(\"üì¶ Loading trained model...\")\n",
    "    package = joblib.load(MODEL_PATH)\n",
    "    model = package['model']\n",
    "    scaler = package['scaler']\n",
    "    print(f\"‚úÖ Model loaded: {package['version']}\")\n",
    "    return model, scaler\n",
    "\n",
    "def load_training_data():\n",
    "    \"\"\"Load training data to get driver/track statistics\"\"\"\n",
    "    print(\"\\nüìä Loading training data for feature engineering...\")\n",
    "    df = pd.read_csv(TRAINING_DATA)\n",
    "    print(f\"‚úÖ Loaded {len(df)} training samples\")\n",
    "    return df\n",
    "\n",
    "def load_2025_races():\n",
    "    \"\"\"Load full 2025 season data\"\"\"\n",
    "    print(\"\\nüìä Loading 2025 season data...\")\n",
    "    df = pd.read_csv(FULL_2025_DATA)\n",
    "    \n",
    "    # Standardize column names\n",
    "    df = df.rename(columns={\n",
    "        'Starting Grid': 'grid',\n",
    "        'Position': 'position',\n",
    "        'Points': 'points',\n",
    "        'Driver': 'driver',\n",
    "        'Track': 'track'\n",
    "    })\n",
    "    \n",
    "    df['year'] = 2025\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(df)} rows from 2025 season\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_last_6_races(df_2025):\n",
    "    \"\"\"Get the last 6 races (19-24) from 2025 data\"\"\"\n",
    "    print(\"\\nüèÅ Identifying last 6 races...\")\n",
    "    \n",
    "    unique_tracks = df_2025['track'].unique()\n",
    "    print(f\"   Total races in 2025: {len(unique_tracks)}\")\n",
    "    print(f\"   All races: {list(unique_tracks)}\")\n",
    "    \n",
    "    if len(unique_tracks) < 19:\n",
    "        print(f\"   ‚ö†Ô∏è  Only {len(unique_tracks)} races available, need at least 19\")\n",
    "        last_6_tracks = unique_tracks[-6:] if len(unique_tracks) >= 6 else unique_tracks\n",
    "    else:\n",
    "        last_6_tracks = unique_tracks[18:]  # Races 19 onwards (0-indexed: position 18+)\n",
    "    \n",
    "    print(f\"\\n   Last 6 races (19-24): {list(last_6_tracks)}\")\n",
    "    \n",
    "    df_last_6 = df_2025[df_2025['track'].isin(last_6_tracks)].copy()\n",
    "    \n",
    "    # Convert position to numeric (handles 'NC', 'DNF', etc.)\n",
    "    df_last_6['position'] = pd.to_numeric(df_last_6['position'], errors='coerce')\n",
    "    df_last_6['grid'] = pd.to_numeric(df_last_6['grid'], errors='coerce')\n",
    "    df_last_6['points'] = pd.to_numeric(df_last_6['points'], errors='coerce')\n",
    "    \n",
    "    # Identify which races have actual results vs need predictions\n",
    "    completed_races = []\n",
    "    future_races = []\n",
    "    \n",
    "    for track in last_6_tracks:\n",
    "        track_data = df_last_6[df_last_6['track'] == track]\n",
    "        if track_data['position'].notna().any():\n",
    "            completed_races.append(track)\n",
    "        else:\n",
    "            future_races.append(track)\n",
    "    \n",
    "    print(f\"\\n   ‚úÖ Completed races ({len(completed_races)}): {completed_races}\")\n",
    "    print(f\"   üîÆ Future races ({len(future_races)}): {future_races}\")\n",
    "    \n",
    "    return df_last_6, last_6_tracks, completed_races, future_races\n",
    "\n",
    "def fill_missing_races_with_historical(df_last_6, last_6_tracks, df_training):\n",
    "    \"\"\"\n",
    "    For races not yet in 2025 data, create entries using:\n",
    "    - Historical grid positions from prior seasons at same track\n",
    "    - Current 2025 driver lineup\n",
    "    \"\"\"\n",
    "    print(\"\\nüîÑ Filling missing races with historical grid data...\")\n",
    "    \n",
    "    # Get current 2025 drivers\n",
    "    drivers_2025 = df_training[df_training['year'] == 2025]['driver'].unique()\n",
    "    \n",
    "    if len(drivers_2025) == 0:\n",
    "        # Fallback to most recent drivers\n",
    "        drivers_2025 = df_training.groupby('driver').tail(1)['driver'].unique()[:20]\n",
    "    \n",
    "    print(f\"   Current driver lineup: {len(drivers_2025)} drivers\")\n",
    "    \n",
    "    # Expected last 6 tracks (typical F1 calendar order for end of season)\n",
    "    # These are the tracks we expect in races 19-24\n",
    "    expected_tracks = ['Singapore', 'United States', 'Mexico', 'Brazil', 'Las Vegas', 'Abu Dhabi']\n",
    "    \n",
    "    missing_tracks = []\n",
    "    filled_data = []\n",
    "    \n",
    "    for track in expected_tracks:\n",
    "        if track not in last_6_tracks:\n",
    "            missing_tracks.append(track)\n",
    "            \n",
    "            # Get historical data for this track\n",
    "            track_history = df_training[df_training['track'] == track].copy()\n",
    "            \n",
    "            if len(track_history) > 0:\n",
    "                print(f\"   üìç {track}: Using historical grid data\")\n",
    "                \n",
    "                # Get most recent year's grid positions for this track\n",
    "                recent_year = track_history['year'].max()\n",
    "                recent_race = track_history[track_history['year'] == recent_year]\n",
    "                \n",
    "                # Create mapping of grid positions from recent race\n",
    "                grid_positions = recent_race.set_index('driver')['grid'].to_dict()\n",
    "                \n",
    "                # Create entries for current 2025 drivers\n",
    "                for driver in drivers_2025:\n",
    "                    # Use historical grid if driver raced there, else estimate\n",
    "                    if driver in grid_positions:\n",
    "                        grid_pos = grid_positions[driver]\n",
    "                    else:\n",
    "                        # New driver - estimate based on their average position\n",
    "                        driver_avg = df_training[df_training['driver'] == driver]['grid'].mean()\n",
    "                        if pd.notna(driver_avg):\n",
    "                            grid_pos = driver_avg\n",
    "                        else:\n",
    "                            grid_pos = 10.0  # Default middle of pack\n",
    "                    \n",
    "                    filled_data.append({\n",
    "                        'year': 2025,\n",
    "                        'track': track,\n",
    "                        'driver': driver,\n",
    "                        'grid': grid_pos,\n",
    "                        'position': np.nan,  # Future race - no result yet\n",
    "                        'points': np.nan\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  {track}: No historical data available, skipping\")\n",
    "    \n",
    "    if filled_data:\n",
    "        df_filled = pd.DataFrame(filled_data)\n",
    "        print(f\"   ‚úÖ Created {len(df_filled)} entries for {len(missing_tracks)} missing races\")\n",
    "        \n",
    "        # Combine with existing last 6 races\n",
    "        df_combined = pd.concat([df_last_6, df_filled], ignore_index=True)\n",
    "        \n",
    "        # Update tracks list\n",
    "        all_last_6_tracks = list(last_6_tracks) + missing_tracks\n",
    "        \n",
    "        return df_combined, all_last_6_tracks, missing_tracks\n",
    "    else:\n",
    "        print(\"   ‚ÑπÔ∏è  No missing races to fill\")\n",
    "        return df_last_6, list(last_6_tracks), []\n",
    "\n",
    "def engineer_features_for_prediction(df_predict, df_training):\n",
    "    \"\"\"\n",
    "    Engineer features for prediction races using training data statistics\n",
    "    \"\"\"\n",
    "    print(\"\\nüîß Engineering features for prediction...\")\n",
    "    \n",
    "    df_predict = df_predict.copy()\n",
    "    \n",
    "    # Calculate statistics from training data (up to race 18)\n",
    "    driver_stats = df_training.groupby('driver').agg({\n",
    "        'position': 'mean',\n",
    "        'points': 'mean'\n",
    "    }).rename(columns={\n",
    "        'position': 'driver_avg_position',\n",
    "        'points': 'driver_avg_points'\n",
    "    })\n",
    "    \n",
    "    # Track statistics from training data\n",
    "    track_stats = df_training.groupby('track').apply(\n",
    "        lambda x: (x['grid'] - x['position']).mean()\n",
    "    ).to_dict()\n",
    "    \n",
    "    # Driver-track combinations\n",
    "    driver_track_stats = df_training.groupby(['driver', 'track'])['position'].mean().to_dict()\n",
    "    \n",
    "    # Merge driver stats\n",
    "    df_predict = df_predict.merge(driver_stats, on='driver', how='left')\n",
    "    \n",
    "    # Add track avg position change\n",
    "    df_predict['track_avg_pos_change'] = df_predict['track'].map(track_stats)\n",
    "    \n",
    "    # Add driver-track average\n",
    "    df_predict['driver_track_avg'] = df_predict.apply(\n",
    "        lambda row: driver_track_stats.get((row['driver'], row['track']), row['driver_avg_position']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # For recent form, use last 3 races from training data per driver\n",
    "    driver_recent = df_training.sort_values(['year', 'track']).groupby('driver').tail(3).groupby('driver')['position'].mean()\n",
    "    df_predict['driver_recent_form'] = df_predict['driver'].map(driver_recent)\n",
    "    \n",
    "    # Fill missing values with driver averages\n",
    "    df_predict['driver_recent_form'] = df_predict['driver_recent_form'].fillna(df_predict['driver_avg_position'])\n",
    "    df_predict['driver_track_avg'] = df_predict['driver_track_avg'].fillna(df_predict['driver_avg_position'])\n",
    "    \n",
    "    # Fill any remaining NaN with medians\n",
    "    for col in ['driver_avg_position', 'driver_avg_points', 'driver_recent_form', \n",
    "                'track_avg_pos_change', 'driver_track_avg']:\n",
    "        if col in df_predict.columns:\n",
    "            df_predict[col] = df_predict[col].fillna(df_predict[col].median())\n",
    "    \n",
    "    print(f\"‚úÖ Features engineered for {len(df_predict)} entries\")\n",
    "    \n",
    "    return df_predict\n",
    "\n",
    "def make_predictions(df, model, scaler):\n",
    "    \"\"\"Make predictions using the trained model\"\"\"\n",
    "    print(\"\\nüîÆ Making predictions...\")\n",
    "    \n",
    "    feature_cols = [\n",
    "        'grid',\n",
    "        'driver_avg_position',\n",
    "        'driver_avg_points',\n",
    "        'driver_recent_form',\n",
    "        'track_avg_pos_change',\n",
    "        'driver_track_avg'\n",
    "    ]\n",
    "    \n",
    "    X = df[feature_cols].copy()\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    predictions = model.predict(X_scaled)\n",
    "    \n",
    "    # Clip predictions to valid range [1, 20]\n",
    "    predictions = np.clip(predictions, 1, 20)\n",
    "    \n",
    "    df['predicted_position'] = predictions\n",
    "    \n",
    "    print(f\"‚úÖ Predictions complete\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def evaluate_predictions(df, completed_races):\n",
    "    \"\"\"Evaluate predictions for completed races\"\"\"\n",
    "    if not completed_races:\n",
    "        print(\"\\n‚ö†Ô∏è  No completed races to evaluate\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\nüìä Evaluating predictions on completed races...\")\n",
    "    \n",
    "    df_completed = df[df['track'].isin(completed_races) & df['position'].notna()].copy()\n",
    "    \n",
    "    if len(df_completed) == 0:\n",
    "        print(\"   No data with actual results\")\n",
    "        return None\n",
    "    \n",
    "    mae = np.mean(np.abs(df_completed['predicted_position'] - df_completed['position']))\n",
    "    rmse = np.sqrt(np.mean((df_completed['predicted_position'] - df_completed['position'])**2))\n",
    "    \n",
    "    print(f\"\\n   MAE: {mae:.2f} positions\")\n",
    "    print(f\"   RMSE: {rmse:.2f} positions\")\n",
    "    \n",
    "    # Show sample comparisons\n",
    "    print(f\"\\n   Sample predictions vs actual:\")\n",
    "    sample = df_completed[['track', 'driver', 'grid', 'position', 'predicted_position']].head(10)\n",
    "    print(sample.to_string(index=False))\n",
    "    \n",
    "    return df_completed\n",
    "\n",
    "def save_predictions(df, output_path):\n",
    "    \"\"\"Save predictions to CSV\"\"\"\n",
    "    print(f\"\\nüíæ Saving predictions to {output_path}...\")\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Sort by track and predicted position\n",
    "    df_sorted = df.sort_values(['track', 'predicted_position'])\n",
    "    \n",
    "    # Select relevant columns\n",
    "    output_cols = ['track', 'driver', 'grid', 'predicted_position', 'position', 'points']\n",
    "    df_output = df_sorted[output_cols].copy()\n",
    "    \n",
    "    df_output.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Saved {len(df_output)} predictions\")\n",
    "    \n",
    "    return df_output\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"F1 2025 Last 6 Races Prediction\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load model and data\n",
    "    model, scaler = load_model()\n",
    "    df_training = load_training_data()\n",
    "    df_2025 = load_2025_races()\n",
    "    \n",
    "    # Get last 6 races\n",
    "    df_last_6, last_6_tracks, completed_races, future_races = get_last_6_races(df_2025)\n",
    "    \n",
    "    # Fill missing races with historical grid data\n",
    "    df_last_6_filled, all_tracks, filled_tracks = fill_missing_races_with_historical(\n",
    "        df_last_6, last_6_tracks, df_training\n",
    "    )\n",
    "    \n",
    "    # Update future races list\n",
    "    all_future_races = future_races + filled_tracks\n",
    "    \n",
    "    # Engineer features\n",
    "    df_with_features = engineer_features_for_prediction(df_last_6_filled, df_training)\n",
    "    \n",
    "    # Make predictions\n",
    "    df_predictions = make_predictions(df_with_features, model, scaler)\n",
    "    \n",
    "    # Evaluate on completed races\n",
    "    if completed_races:\n",
    "        evaluate_predictions(df_predictions, completed_races)\n",
    "    \n",
    "    # Save predictions\n",
    "    df_output = save_predictions(df_predictions, OUTPUT_PATH)\n",
    "    \n",
    "    # Show predictions for future/filled races\n",
    "    if all_future_races:\n",
    "        print(\"\\nüîÆ Predictions for future/simulated races:\")\n",
    "        df_future = df_predictions[df_predictions['track'].isin(all_future_races)].sort_values(['track', 'predicted_position'])\n",
    "        for track in all_future_races:\n",
    "            track_data = df_future[df_future['track'] == track]\n",
    "            if len(track_data) > 0:\n",
    "                is_filled = track in filled_tracks\n",
    "                status = \"üìä Historical grid\" if is_filled else \"üîÆ Future\"\n",
    "                print(f\"\\n   {status} - {track}:\")\n",
    "                track_pred = track_data[['driver', 'grid', 'predicted_position']].head(10)\n",
    "                print(track_pred.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ Predictions complete!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nüìÇ Results saved to: {OUTPUT_PATH}\")\n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    print(f\"   Total races predicted: {len(all_tracks)}\")\n",
    "    print(f\"   Completed races: {len(completed_races)}\")\n",
    "    print(f\"   Future/Simulated races: {len(all_future_races)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
